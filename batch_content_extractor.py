"""
æ‰¹é‡å†…å®¹æå–å™¨

åŠ¨æ€ä¿®æ”¹URLä¸­çš„æ•°å­—ï¼ˆ1-65ï¼‰ï¼Œæ‰¹é‡æå–æ‡‚è½¦å¸ç¤¾åŒºå†…å®¹
"""

import sys
import os
import time
import json
from datetime import datetime
from typing import List, Dict, Any

# æ·»åŠ skillsç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'skills'))

from enhanced_content_extractor import EnhancedContentExtractor


class BatchContentExtractor:
    """æ‰¹é‡å†…å®¹æå–å™¨"""
    
    def __init__(self):
        self.extractor = EnhancedContentExtractor()
        self.base_url = "https://www.dongchedi.com/community/9118/hot-release-{}"
        self.all_posts = []
        self.failed_urls = []
        self.success_count = 0
        self.total_count = 0
        
    def extract_batch(self, start_num: int = 1, end_num: int = 65, delay: float = 2.0):
        """
        æ‰¹é‡æå–å†…å®¹
        
        Args:
            start_num: èµ·å§‹æ•°å­—
            end_num: ç»“æŸæ•°å­—
            delay: æ¯æ¬¡è¯·æ±‚ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰
        """
        print(f"å¼€å§‹æ‰¹é‡æå–å†…å®¹ï¼ŒèŒƒå›´: {start_num}-{end_num}")
        print(f"æ¯æ¬¡è¯·æ±‚é—´éš”: {delay}ç§’")
        print("=" * 60)
        
        self.total_count = end_num - start_num + 1
        
        for num in range(start_num, end_num + 1):
            url = self.base_url.format(num)
            
            print(f"\n[{num}/{end_num}] æ­£åœ¨å¤„ç†: {url}")
            
            try:
                # æ‰§è¡Œå†…å®¹æå–
                result = self.extractor.analyze_and_extract(url)
                
                if result["success"]:
                    posts = result.get("posts", [])
                    print(f"âœ… æˆåŠŸæå– {len(posts)} æ¡å†…å®¹")
                    
                    # ä¸ºæ¯ä¸ªå¸–å­æ·»åŠ æ¥æºURLä¿¡æ¯
                    for post in posts:
                        post['source_url'] = url
                        post['page_number'] = num
                    
                    self.all_posts.extend(posts)
                    self.success_count += 1
                    
                else:
                    error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                    print(f"âŒ æå–å¤±è´¥: {error_msg}")
                    self.failed_urls.append({"url": url, "error": error_msg})
                
            except Exception as e:
                print(f"âŒ å¤„ç†å¼‚å¸¸: {str(e)}")
                self.failed_urls.append({"url": url, "error": str(e)})
            
            # æ˜¾ç¤ºè¿›åº¦ç»Ÿè®¡
            self._print_progress_stats()
            
            # å»¶è¿Ÿä»¥é¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
            if num < end_num:
                print(f"ç­‰å¾… {delay} ç§’...")
                time.sleep(delay)
        
        print("\n" + "=" * 60)
        print("æ‰¹é‡æå–å®Œæˆï¼")
        self._print_final_stats()
        
        # ä¿å­˜ç»“æœ
        self._save_results()
    
    def _print_progress_stats(self):
        """æ‰“å°è¿›åº¦ç»Ÿè®¡"""
        processed = self.success_count + len(self.failed_urls)
        success_rate = (self.success_count / processed * 100) if processed > 0 else 0
        
        print(f"è¿›åº¦: {processed}/{self.total_count} | "
              f"æˆåŠŸ: {self.success_count} | "
              f"å¤±è´¥: {len(self.failed_urls)} | "
              f"æˆåŠŸç‡: {success_rate:.1f}% | "
              f"æ€»å†…å®¹æ•°: {len(self.all_posts)}")
    
    def _print_final_stats(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡"""
        print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print(f"   æ€»é¡µé¢æ•°: {self.total_count}")
        print(f"   æˆåŠŸé¡µé¢: {self.success_count}")
        print(f"   å¤±è´¥é¡µé¢: {len(self.failed_urls)}")
        print(f"   æˆåŠŸç‡: {(self.success_count / self.total_count * 100):.1f}%")
        print(f"   æ€»å†…å®¹æ•°: {len(self.all_posts)}")
        
        if self.failed_urls:
            print(f"\nâŒ å¤±è´¥çš„URL:")
            for failed in self.failed_urls:
                print(f"   {failed['url']} - {failed['error']}")
    
    def _save_results(self):
        """ä¿å­˜æå–ç»“æœ"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        
        # ç¡®ä¿reportç›®å½•å­˜åœ¨
        report_dir = os.path.join(os.path.dirname(__file__), 'report')
        os.makedirs(report_dir, exist_ok=True)
        
        # ä¿å­˜JSONæ ¼å¼
        json_filename = f"batch_extracted_content_{timestamp}.json"
        json_filepath = os.path.join(report_dir, json_filename)
        
        json_data = {
            "extraction_info": {
                "timestamp": timestamp,
                "total_pages": self.total_count,
                "successful_pages": self.success_count,
                "failed_pages": len(self.failed_urls),
                "total_posts": len(self.all_posts),
                "base_url_pattern": self.base_url,
                "extraction_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            },
            "failed_urls": self.failed_urls,
            "posts": self.all_posts
        }
        
        with open(json_filepath, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ JSONæ–‡ä»¶å·²ä¿å­˜: {json_filepath}")
        
        # ä¿å­˜æ–‡æœ¬æ ¼å¼
        txt_filename = f"batch_extracted_content_{timestamp}.txt"
        txt_filepath = os.path.join(report_dir, txt_filename)
        
        with open(txt_filepath, 'w', encoding='utf-8') as f:
            f.write("æ‡‚è½¦å¸ç¤¾åŒºæ‰¹é‡å†…å®¹æå–ç»“æœ\n")
            f.write("=" * 60 + "\n\n")
            
            # å†™å…¥æå–ä¿¡æ¯
            f.write(f"æå–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"URLæ¨¡å¼: {self.base_url}\n")
            f.write(f"é¡µé¢èŒƒå›´: 1-65\n")
            f.write(f"æ€»é¡µé¢æ•°: {self.total_count}\n")
            f.write(f"æˆåŠŸé¡µé¢: {self.success_count}\n")
            f.write(f"å¤±è´¥é¡µé¢: {len(self.failed_urls)}\n")
            f.write(f"æ€»å†…å®¹æ•°: {len(self.all_posts)}\n")
            f.write("=" * 60 + "\n\n")
            
            # å†™å…¥å¤±è´¥çš„URLï¼ˆå¦‚æœæœ‰ï¼‰
            if self.failed_urls:
                f.write("å¤±è´¥çš„URLåˆ—è¡¨:\n")
                f.write("-" * 30 + "\n")
                for failed in self.failed_urls:
                    f.write(f"URL: {failed['url']}\n")
                    f.write(f"é”™è¯¯: {failed['error']}\n\n")
                f.write("=" * 60 + "\n\n")
            
            # å†™å…¥æ‰€æœ‰æå–çš„å†…å®¹
            f.write("æå–çš„å†…å®¹åˆ—è¡¨:\n")
            f.write("=" * 60 + "\n\n")
            
            for i, post in enumerate(self.all_posts, 1):
                f.write(f"ã€å†…å®¹ {i}ã€‘\n")
                f.write(f"æ¥æºé¡µé¢: {post.get('page_number', 'N/A')}\n")
                f.write(f"æ¥æºURL: {post.get('source_url', 'N/A')}\n")
                
                if post.get('username'):
                    f.write(f"ç”¨æˆ·: {post['username']}\n")
                
                if post.get('timestamp'):
                    f.write(f"æ—¶é—´: {post['timestamp']}\n")
                
                interactions = post.get('interactions', {})
                if interactions:
                    interaction_parts = []
                    for key, value in interactions.items():
                        if key == 'likes':
                            interaction_parts.append(f"likes: {value}")
                        elif key == 'comments':
                            interaction_parts.append(f"comments: {value}")
                        elif key == 'shares':
                            interaction_parts.append(f"shares: {value}")
                        elif key == 'views':
                            interaction_parts.append(f"views: {value}")
                    
                    if interaction_parts:
                        f.write(f"äº’åŠ¨: {', '.join(interaction_parts)}\n")
                
                f.write(f"å†…å®¹: {post.get('content', '')}\n")
                
                if post.get('images'):
                    f.write(f"å›¾ç‰‡: {len(post['images'])} å¼ \n")
                
                if 'quality_score' in post:
                    f.write(f"è´¨é‡åˆ†æ•°: {post['quality_score']:.2f}\n")
                
                f.write("-" * 60 + "\n\n")
        
        print(f"ğŸ“„ æ–‡æœ¬æ–‡ä»¶å·²ä¿å­˜: {txt_filepath}")
        
        return json_filepath, txt_filepath


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš— æ‡‚è½¦å¸ç¤¾åŒºæ‰¹é‡å†…å®¹æå–å™¨")
    print("=" * 60)
    
    # åˆ›å»ºæ‰¹é‡æå–å™¨
    batch_extractor = BatchContentExtractor()
    
    # å¼€å§‹æ‰¹é‡æå–
    try:
        batch_extractor.extract_batch(
            start_num=1,
            end_num=65,
            delay=2.0  # 2ç§’å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        )
        
        print("\nğŸ‰ æ‰¹é‡æå–ä»»åŠ¡å®Œæˆï¼")
        print("æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° report ç›®å½•ä¸­ã€‚")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­äº†æå–è¿‡ç¨‹")
        print("æ­£åœ¨ä¿å­˜å·²æå–çš„å†…å®¹...")
        batch_extractor._save_results()
        
    except Exception as e:
        print(f"\nâŒ æ‰¹é‡æå–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        print("æ­£åœ¨ä¿å­˜å·²æå–çš„å†…å®¹...")
        batch_extractor._save_results()


if __name__ == "__main__":
    main()