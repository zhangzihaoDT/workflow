#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CMè½¦å‹é¢„å”®åˆ†æè„šæœ¬
åˆ†æCM0ã€CM1ã€CM2è½¦å‹çš„é¢„å”®ç´¯è®¡å°è®¢æ•°ã€å°è®¢ç•™å­˜é”å•æ•°å’Œå°è®¢è½¬åŒ–ç‡

å‚è€ƒ order_trend_monitor.py çš„è®¡ç®—é€»è¾‘
"""

import pandas as pd
import numpy as np
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple, Any

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ•°æ®è·¯å¾„é…ç½®
DATA_PATH = "/Users/zihao_/Documents/coding/dataset/formatted/intention_order_analysis.parquet"
BUSINESS_DEF_PATH = "/Users/zihao_/Documents/github/W35_workflow/business_definition.json"

class CMVehiclePresaleAnalyzer:
    """CMè½¦å‹é¢„å”®åˆ†æå™¨"""
    
    def __init__(self):
        self.df = None
        self.business_definition = None
        self.analysis_results = {}
        
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        try:
            logger.info("åŠ è½½æ•°æ®æ–‡ä»¶...")
            self.df = pd.read_parquet(DATA_PATH)
            logger.info(f"æ•°æ®åŠ è½½æˆåŠŸï¼Œå…±{len(self.df)}æ¡è®°å½•")
            
            # è½¬æ¢æ—¶é—´åˆ—
            time_columns = ['Intention_Payment_Time', 'Lock_Time', 'intention_refund_time', 'first_assign_time']
            for col in time_columns:
                if col in self.df.columns:
                    self.df[col] = pd.to_datetime(self.df[col], errors='coerce')
                    
        except Exception as e:
            logger.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise
            
    def load_business_definition(self):
        """åŠ è½½ä¸šåŠ¡å®šä¹‰"""
        try:
            logger.info("åŠ è½½ä¸šåŠ¡å®šä¹‰æ–‡ä»¶...")
            with open(BUSINESS_DEF_PATH, 'r', encoding='utf-8') as f:
                self.business_definition = json.load(f)
            logger.info("ä¸šåŠ¡å®šä¹‰åŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.error(f"ä¸šåŠ¡å®šä¹‰åŠ è½½å¤±è´¥: {e}")
            raise
            
    def get_vehicle_period(self, vehicle: str) -> Dict[str, str]:
        """è·å–è½¦å‹çš„é¢„å”®å‘¨æœŸ"""
        if not self.business_definition or 'time_periods' not in self.business_definition:
            return None
        return self.business_definition['time_periods'].get(vehicle)
        
    def calculate_days_from_start(self, vehicle: str, date: datetime) -> int:
        """è®¡ç®—ä»é¢„å”®å¼€å§‹çš„å¤©æ•°"""
        period = self.get_vehicle_period(vehicle)
        if not period:
            return 0
        start_date = pd.to_datetime(period['start'])
        return (date - start_date).days + 1
        
    def analyze_time_interval_patterns(self, vehicle: str) -> Dict[str, Any]:
        """åˆ†æLock_Timeå’ŒIntention_Payment_Timeçš„æ—¶é—´å·®æ¨¡å¼"""
        logger.info(f"åˆ†æ{vehicle}è½¦å‹çš„æ—¶é—´é—´éš”æ¨¡å¼...")
        
        # è·å–è½¦å‹æ•°æ®
        vehicle_data = self.df[self.df['è½¦å‹åˆ†ç»„'] == vehicle].copy()
        if len(vehicle_data) == 0:
            logger.warning(f"{vehicle}è½¦å‹æ— æ•°æ®")
            return None
            
        # è·å–é¢„å”®å‘¨æœŸ
        period = self.get_vehicle_period(vehicle)
        if not period:
            logger.warning(f"{vehicle}è½¦å‹æ— é¢„å”®å‘¨æœŸå®šä¹‰")
            return None
            
        start_date = pd.to_datetime(period['start'])
        end_date = pd.to_datetime(period['end'])
        
        # ç­›é€‰é¢„å”®æœŸé—´çš„æ•°æ®
        presale_data = vehicle_data[
            (vehicle_data['Intention_Payment_Time'] >= start_date) & 
            (vehicle_data['Intention_Payment_Time'] <= end_date)
        ].copy()
        
        if len(presale_data) == 0:
            logger.warning(f"{vehicle}è½¦å‹é¢„å”®æœŸé—´æ— æ•°æ®")
            return None
            
        # ç­›é€‰æœ‰é”å•æ—¶é—´çš„è®¢å•
        lock_cutoff_date = end_date + timedelta(days=1)
        locked_orders = presale_data[
            (presale_data['Lock_Time'].notna()) & 
            (presale_data['Intention_Payment_Time'].notna()) & 
            (presale_data['Lock_Time'] < pd.Timestamp(lock_cutoff_date))
        ].copy()
        
        if len(locked_orders) == 0:
            logger.warning(f"{vehicle}è½¦å‹æ— æœ‰æ•ˆé”å•æ•°æ®")
            return {
                'vehicle': vehicle,
                'total_presale_orders': len(presale_data),
                'locked_orders': 0,
                'time_intervals': [],
                'interval_stats': {}
            }
            
        # è®¡ç®—æ—¶é—´å·®ï¼ˆå¤©æ•°ï¼‰
        locked_orders['time_interval_days'] = (
            locked_orders['Lock_Time'] - locked_orders['Intention_Payment_Time']
        ).dt.days
        
        # è¿‡æ»¤è´Ÿå€¼å’Œå¼‚å¸¸å€¼ï¼ˆè¶…è¿‡365å¤©çš„ï¼‰
        locked_orders = locked_orders[
            (locked_orders['time_interval_days'] >= 0) & 
            (locked_orders['time_interval_days'] <= 365)
        ]
        
        if len(locked_orders) == 0:
            logger.warning(f"{vehicle}è½¦å‹æ— æœ‰æ•ˆæ—¶é—´é—´éš”æ•°æ®")
            return {
                'vehicle': vehicle,
                'total_presale_orders': len(presale_data),
                'locked_orders': 0,
                'time_intervals': [],
                'interval_stats': {}
            }
            
        # æŒ‰æ—¶é—´é—´éš”åˆ†ç»„ç»Ÿè®¡
        interval_groups = [
            (0, 0, 'å½“å¤©'),
            (1, 3, '1-3å¤©'),
            (4, 7, '4-7å¤©'),
            (8, 14, '8-14å¤©'),
            (15, 30, '15-30å¤©'),
            (31, 60, '31-60å¤©'),
            (61, 365, '61å¤©ä»¥ä¸Š')
        ]
        
        interval_stats = {}
        total_presale = len(presale_data)
        total_locked = len(locked_orders)
        
        for min_days, max_days, label in interval_groups:
            if min_days == max_days:
                interval_data = locked_orders[locked_orders['time_interval_days'] == min_days]
            else:
                interval_data = locked_orders[
                    (locked_orders['time_interval_days'] >= min_days) & 
                    (locked_orders['time_interval_days'] <= max_days)
                ]
            
            count = len(interval_data)
            percentage_of_locked = (count / total_locked * 100) if total_locked > 0 else 0
            percentage_of_total = (count / total_presale * 100) if total_presale > 0 else 0
            
            interval_stats[label] = {
                'min_days': min_days,
                'max_days': max_days,
                'count': count,
                'percentage_of_locked': round(percentage_of_locked, 2),
                'percentage_of_total': round(percentage_of_total, 2)
            }
        
        # ç»Ÿè®¡ä¿¡æ¯
        time_intervals = locked_orders['time_interval_days'].tolist()
        time_intervals.sort(reverse=True)  # é™åºæ’åº
        
        stats = {
            'mean': round(locked_orders['time_interval_days'].mean(), 2),
            'median': round(locked_orders['time_interval_days'].median(), 2),
            'std': round(locked_orders['time_interval_days'].std(), 2),
            'min': int(locked_orders['time_interval_days'].min()),
            'max': int(locked_orders['time_interval_days'].max()),
            'q25': round(locked_orders['time_interval_days'].quantile(0.25), 2),
            'q75': round(locked_orders['time_interval_days'].quantile(0.75), 2)
        }
        
        result = {
            'vehicle': vehicle,
            'total_presale_orders': total_presale,
            'locked_orders': total_locked,
            'overall_lock_rate': round(total_locked / total_presale * 100, 2),
            'time_intervals': time_intervals[:100],  # åªä¿ç•™å‰100ä¸ªæœ€å¤§å€¼
            'interval_stats': interval_stats,
            'descriptive_stats': stats
        }
        
        logger.info(f"{vehicle}è½¦å‹æ—¶é—´é—´éš”åˆ†æå®Œæˆ: é”å•{total_locked}å•, å¹³å‡é—´éš”{stats['mean']:.1f}å¤©")
        return result
        
    def analyze_all_vehicles_time_intervals(self) -> Dict[str, Any]:
        """åˆ†ææ‰€æœ‰è½¦å‹çš„æ—¶é—´é—´éš”æ¨¡å¼å¹¶è¿›è¡Œå¯¹æ¯”"""
        logger.info("å¼€å§‹åˆ†ææ‰€æœ‰è½¦å‹çš„æ—¶é—´é—´éš”æ¨¡å¼...")
        
        vehicles = ['CM0', 'CM1', 'CM2']
        all_results = {}
        
        # åˆ†ææ¯ä¸ªè½¦å‹
        for vehicle in vehicles:
            result = self.analyze_time_interval_patterns(vehicle)
            if result:
                all_results[vehicle] = result
        
        if not all_results:
            logger.warning("æ— æœ‰æ•ˆçš„æ—¶é—´é—´éš”åˆ†æç»“æœ")
            return {}
            
        # ç”Ÿæˆå¯¹æ¯”åˆ†æ
        comparison = {
            'vehicles_analyzed': list(all_results.keys()),
            'individual_results': all_results,
            'comparison_summary': {}
        }
        
        # å¯¹æ¯”ç»Ÿè®¡
        summary = {}
        for vehicle, data in all_results.items():
            summary[vehicle] = {
                'total_presale_orders': data['total_presale_orders'],
                'locked_orders': data['locked_orders'],
                'overall_lock_rate': data['overall_lock_rate'],
                'avg_interval_days': data['descriptive_stats']['mean'],
                'median_interval_days': data['descriptive_stats']['median'],
                'max_interval_days': data['descriptive_stats']['max'],
                'min_interval_days': data['descriptive_stats']['min']
            }
        
        comparison['comparison_summary'] = summary
        
        # æŒ‰ä¸åŒæ—¶é—´é—´éš”çš„é”å•ç‡å¯¹æ¯”
        interval_comparison = {}
        interval_labels = ['å½“å¤©', '1-3å¤©', '4-7å¤©', '8-14å¤©', '15-30å¤©', '31-60å¤©', '61å¤©ä»¥ä¸Š']
        
        for label in interval_labels:
            interval_comparison[label] = {}
            for vehicle, data in all_results.items():
                if label in data['interval_stats']:
                    interval_comparison[label][vehicle] = {
                        'count': data['interval_stats'][label]['count'],
                        'percentage_of_locked': data['interval_stats'][label]['percentage_of_locked'],
                        'percentage_of_total': data['interval_stats'][label]['percentage_of_total']
                    }
                else:
                    interval_comparison[label][vehicle] = {
                        'count': 0,
                        'percentage_of_locked': 0,
                        'percentage_of_total': 0
                    }
        
        comparison['interval_comparison'] = interval_comparison
        
        # æ’åºåˆ†æï¼šæŒ‰å¹³å‡æ—¶é—´é—´éš”æ’åº
        sorted_by_avg_interval = sorted(
            summary.items(), 
            key=lambda x: x[1]['avg_interval_days'], 
            reverse=True
        )
        
        # æ’åºåˆ†æï¼šæŒ‰é”å•ç‡æ’åº
        sorted_by_lock_rate = sorted(
            summary.items(), 
            key=lambda x: x[1]['overall_lock_rate'], 
            reverse=True
        )
        
        comparison['rankings'] = {
            'by_avg_interval_desc': [item[0] for item in sorted_by_avg_interval],
            'by_lock_rate_desc': [item[0] for item in sorted_by_lock_rate]
        }
        
        logger.info(f"æ—¶é—´é—´éš”å¯¹æ¯”åˆ†æå®Œæˆï¼Œåˆ†æäº†{len(all_results)}ä¸ªè½¦å‹")
        return comparison
        
    def analyze_vehicle_presale(self, vehicle: str) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªè½¦å‹çš„é¢„å”®æ•°æ®"""
        logger.info(f"åˆ†æ{vehicle}è½¦å‹é¢„å”®æ•°æ®...")
        
        # è·å–è½¦å‹æ•°æ®
        vehicle_data = self.df[self.df['è½¦å‹åˆ†ç»„'] == vehicle].copy()
        if len(vehicle_data) == 0:
            logger.warning(f"{vehicle}è½¦å‹æ— æ•°æ®")
            return None
            
        # è·å–é¢„å”®å‘¨æœŸ
        period = self.get_vehicle_period(vehicle)
        if not period:
            logger.warning(f"{vehicle}è½¦å‹æ— é¢„å”®å‘¨æœŸå®šä¹‰")
            return None
            
        start_date = pd.to_datetime(period['start'])
        end_date = pd.to_datetime(period['end'])
        
        # ç­›é€‰é¢„å”®æœŸé—´çš„æ•°æ®
        presale_data = vehicle_data[
            (vehicle_data['Intention_Payment_Time'] >= start_date) & 
            (vehicle_data['Intention_Payment_Time'] <= end_date)
        ].copy()
        
        if len(presale_data) == 0:
            logger.warning(f"{vehicle}è½¦å‹é¢„å”®æœŸé—´æ— æ•°æ®")
            return None
            
        # è®¡ç®—é¢„å”®ç´¯è®¡å°è®¢æ•°
        total_presale_orders = len(presale_data)
        
        # è®¡ç®—å°è®¢ç•™å­˜é”å•æ•°ï¼šåŒæ—¶å«æœ‰Lock_Timeã€Intention_Payment_Timeï¼Œä¸”Lock_Time < é¢„å”®ç»“æŸæ—¥æœŸ+30æ—¥
        # å‚è€ƒorder_trend_monitor.pyçš„è®¡ç®—é€»è¾‘
        lock_cutoff_date = end_date + timedelta(days=1)
        lock_orders = presale_data[
            (presale_data['Lock_Time'].notna()) & 
            (presale_data['Intention_Payment_Time'].notna()) & 
            (presale_data['Lock_Time'] < pd.Timestamp(lock_cutoff_date))
        ]
        retained_locks = len(lock_orders)
        
        # è®¡ç®—å°è®¢è½¬åŒ–ç‡
        conversion_rate = (retained_locks / total_presale_orders * 100) if total_presale_orders > 0 else 0
        
        # æŒ‰æ—¥ç»Ÿè®¡é¢„å”®è®¢å•æ•°
        presale_data['date'] = presale_data['Intention_Payment_Time'].dt.date
        daily_orders = presale_data.groupby('date').size().reset_index(name='orders')
        daily_orders['date'] = pd.to_datetime(daily_orders['date'])
        daily_orders = daily_orders.sort_values('date')
        daily_orders['cumulative'] = daily_orders['orders'].cumsum()
        daily_orders['days_from_start'] = daily_orders['date'].apply(
            lambda x: self.calculate_days_from_start(vehicle, x.to_pydatetime())
        )
        
        # æŒ‰æ—¥ç»Ÿè®¡é”å•æ•°ï¼ˆä½¿ç”¨æ­£ç¡®çš„é”å•æ¡ä»¶ï¼‰
        daily_locks = []
        for _, row in daily_orders.iterrows():
            day_orders = presale_data[presale_data['date'] == row['date'].date()]
            # ä½¿ç”¨ä¸æ€»ä½“è®¡ç®—ä¸€è‡´çš„é”å•æ¡ä»¶
            day_locks = day_orders[
                (day_orders['Lock_Time'].notna()) & 
                (day_orders['Intention_Payment_Time'].notna()) & 
                (day_orders['Lock_Time'] < pd.Timestamp(lock_cutoff_date))
            ]
            daily_locks.append({
                'date': row['date'],
                'days_from_start': row['days_from_start'],
                'orders': row['orders'],
                'cumulative_orders': row['cumulative'],
                'locks': len(day_locks),
                'conversion_rate': (len(day_locks) / row['orders'] * 100) if row['orders'] > 0 else 0
            })
        
        daily_locks_df = pd.DataFrame(daily_locks)
        
        # è®¡ç®—é¢„å”®å‘¨æœŸé•¿åº¦
        presale_days = (end_date - start_date).days + 1
        
        result = {
            'vehicle': vehicle,
            'period': period,
            'presale_days': presale_days,
            'total_presale_orders': total_presale_orders,
            'retained_locks': retained_locks,
            'conversion_rate': round(conversion_rate, 2),
            'daily_data': daily_locks_df.to_dict('records'),
            'summary': {
                'start_date': start_date.strftime('%Y-%m-%d'),
                'end_date': end_date.strftime('%Y-%m-%d'),
                'avg_daily_orders': round(total_presale_orders / presale_days, 1),
                'peak_daily_orders': daily_orders['orders'].max() if not daily_orders.empty else 0,
                'peak_date': daily_orders.loc[daily_orders['orders'].idxmax(), 'date'].strftime('%Y-%m-%d') if not daily_orders.empty else None
            }
        }
        
        logger.info(f"{vehicle}è½¦å‹åˆ†æå®Œæˆ: é¢„å”®{total_presale_orders}å•, ç•™å­˜é”å•{retained_locks}å•, è½¬åŒ–ç‡{conversion_rate:.2f}%")
        return result
        
    def analyze_all_cm_vehicles(self) -> Dict[str, Any]:
        """åˆ†ææ‰€æœ‰CMè½¦å‹"""
        logger.info("å¼€å§‹åˆ†ææ‰€æœ‰CMè½¦å‹...")
        
        cm_vehicles = ['CM0', 'CM1', 'CM2']
        results = {}
        
        for vehicle in cm_vehicles:
            result = self.analyze_vehicle_presale(vehicle)
            if result:
                results[vehicle] = result
        
        # æ·»åŠ æ—¶é—´é—´éš”åˆ†æ
        logger.info("å¼€å§‹æ—¶é—´é—´éš”åˆ†æ...")
        time_interval_analysis = self.analyze_all_vehicles_time_intervals()
        
        # å°†æ—¶é—´é—´éš”åˆ†æç»“æœæ·»åŠ åˆ°æ€»ç»“æœä¸­
        final_results = {
            'vehicle_analysis': results,
            'time_interval_analysis': time_interval_analysis
        }
                 
        self.analysis_results = final_results
        return final_results
        
    def generate_comparison_table(self) -> pd.DataFrame:
        """ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼"""
        if not self.analysis_results or 'vehicle_analysis' not in self.analysis_results:
            return pd.DataFrame()
            
        vehicle_results = self.analysis_results['vehicle_analysis']
        comparison_data = []
        for vehicle, data in vehicle_results.items():
            comparison_data.append({
                'è½¦å‹åˆ†ç»„': vehicle,
                'é¢„å”®å‘¨æœŸ': f"{data['summary']['start_date']} è‡³ {data['summary']['end_date']}",
                'é¢„å”®å¤©æ•°': data['presale_days'],
                'é¢„å”®ç´¯è®¡å°è®¢æ•°': data['total_presale_orders'],
                'å°è®¢ç•™å­˜é”å•æ•°': data['retained_locks'],
                'å°è®¢è½¬åŒ–ç‡(%)': data['conversion_rate'],
                'æ—¥å‡è®¢å•æ•°': data['summary']['avg_daily_orders'],
                'å³°å€¼æ—¥è®¢å•æ•°': data['summary']['peak_daily_orders'],
                'å³°å€¼æ—¥æœŸ': data['summary']['peak_date']
            })
            
        return pd.DataFrame(comparison_data)
        
    def generate_markdown_report(self) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š"""
        if not self.analysis_results:
            return "# CMè½¦å‹é¢„å”®åˆ†ææŠ¥å‘Š\n\n**é”™è¯¯**: æ— åˆ†æç»“æœæ•°æ®"
            
        report = []
        report.append("# CMè½¦å‹é¢„å”®åˆ†ææŠ¥å‘Š")
        report.append("")
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # æ¦‚è§ˆ
        report.append("## ğŸ“Š åˆ†ææ¦‚è§ˆ")
        report.append("")
        report.append("æœ¬æŠ¥å‘Šåˆ†æCM0ã€CM1ã€CM2ä¸‰ä¸ªè½¦å‹çš„é¢„å”®è¡¨ç°ï¼Œé‡ç‚¹å…³æ³¨ä»¥ä¸‹æŒ‡æ ‡ï¼š")
        report.append("- **é¢„å”®ç´¯è®¡å°è®¢æ•°**: é¢„å”®æœŸé—´çš„æ€»è®¢å•æ•°")
        report.append("- **å°è®¢ç•™å­˜é”å•æ•°**: é¢„å”®è®¢å•ä¸­æœ€ç»ˆé”å•çš„æ•°é‡")
        report.append("- **å°è®¢è½¬åŒ–ç‡**: ç•™å­˜é”å•æ•°å é¢„å”®è®¢å•æ•°çš„æ¯”ä¾‹")
        report.append("")
        
        # å¯¹æ¯”è¡¨æ ¼
        comparison_df = self.generate_comparison_table()
        if not comparison_df.empty:
            report.append("## ğŸ“ˆ è½¦å‹å¯¹æ¯”è¡¨")
            report.append("")
            report.append(comparison_df.to_markdown(index=False))
            report.append("")
            
        # è¯¦ç»†åˆ†æ
        report.append("## ğŸ” è¯¦ç»†åˆ†æ")
        report.append("")
        
        vehicle_results = self.analysis_results.get('vehicle_analysis', {})
        for vehicle in ['CM0', 'CM1', 'CM2']:
            if vehicle in vehicle_results:
                data = vehicle_results[vehicle]
                report.append(f"### {vehicle}è½¦å‹")
                report.append("")
                report.append(f"**é¢„å”®å‘¨æœŸ**: {data['summary']['start_date']} è‡³ {data['summary']['end_date']} ({data['presale_days']}å¤©)")
                report.append("")
                report.append("**æ ¸å¿ƒæŒ‡æ ‡**:")
                report.append(f"- é¢„å”®ç´¯è®¡å°è®¢æ•°: **{data['total_presale_orders']:,}å•**")
                report.append(f"- å°è®¢ç•™å­˜é”å•æ•°: **{data['retained_locks']:,}å•**")
                report.append(f"- å°è®¢è½¬åŒ–ç‡: **{data['conversion_rate']:.2f}%**")
                report.append("")
                report.append("**è¡¨ç°ç‰¹å¾**:")
                report.append(f"- æ—¥å‡è®¢å•æ•°: {data['summary']['avg_daily_orders']}å•")
                report.append(f"- å³°å€¼æ—¥è®¢å•æ•°: {data['summary']['peak_daily_orders']}å•")
                report.append(f"- å³°å€¼æ—¥æœŸ: {data['summary']['peak_date']}")
                report.append("")
                
                # æ¯æ—¥æ•°æ®è¡¨æ ¼ï¼ˆä»…æ˜¾ç¤ºå‰10å¤©å’Œå5å¤©ï¼‰
                daily_data = data['daily_data']
                if daily_data:
                    report.append("**æ¯æ—¥è®¢å•æ•°æ®** (å‰10å¤©):")
                    report.append("")
                    report.append("| æ—¥æœŸ | ç¬¬Næ—¥ | å½“æ—¥è®¢å• | ç´¯è®¡è®¢å• | å½“æ—¥é”å• | å½“æ—¥è½¬åŒ–ç‡(%) |")
                    report.append("|------|-------|----------|----------|----------|---------------|")
                    
                    # æ˜¾ç¤ºå‰10å¤©
                    for i, day_data in enumerate(daily_data[:10]):
                        date_str = pd.to_datetime(day_data['date']).strftime('%m-%d')
                        report.append(f"| {date_str} | ç¬¬{day_data['days_from_start']}æ—¥ | {day_data['orders']} | {day_data['cumulative_orders']} | {day_data['locks']} | {day_data['conversion_rate']:.1f}% |")
                    
                    if len(daily_data) > 10:
                        report.append("| ... | ... | ... | ... | ... | ... |")
                        
                    report.append("")
            else:
                report.append(f"### {vehicle}è½¦å‹")
                report.append("")
                report.append("**âš ï¸ æ— æ•°æ®æˆ–åˆ†æå¤±è´¥**")
                report.append("")
                
        # æ—¶é—´é—´éš”åˆ†æ
        if 'time_interval_analysis' in self.analysis_results:
            time_analysis = self.analysis_results['time_interval_analysis']
            report.append("## â±ï¸ æ—¶é—´é—´éš”åˆ†æ")
            report.append("")
            report.append("åˆ†æé¢„å”®è®¢å•ä»æ”¯ä»˜æ„å‘é‡‘åˆ°é”å•çš„æ—¶é—´é—´éš”æ¨¡å¼ï¼š")
            report.append("")
            
            if 'comparison_summary' in time_analysis:
                summary = time_analysis['comparison_summary']
                report.append("### æ—¶é—´é—´éš”å¯¹æ¯”")
                report.append("")
                report.append("| è½¦å‹ | å¹³å‡é—´éš”(å¤©) | ä¸­ä½æ•°é—´éš”(å¤©) | æœ€å¤§é—´éš”(å¤©) | é”å•ç‡(%) |")
                report.append("|------|-------------|---------------|-------------|-----------|")
                
                for vehicle in ['CM0', 'CM1', 'CM2']:
                    if vehicle in summary:
                        data = summary[vehicle]
                        report.append(f"| {vehicle} | {data['avg_interval_days']:.1f} | {data['median_interval_days']:.1f} | {data['max_interval_days']} | {data['overall_lock_rate']:.1f}% |")
                
                report.append("")
            
            if 'interval_comparison' in time_analysis:
                interval_comp = time_analysis['interval_comparison']
                report.append("### ä¸åŒæ—¶é—´æ®µé”å•åˆ†å¸ƒ")
                report.append("")
                report.append("| æ—¶é—´æ®µ | CM0é”å•æ•° | CM1é”å•æ•° | CM2é”å•æ•° |")
                report.append("|--------|----------|----------|----------|")
                
                for interval_label in ['å½“å¤©', '1-3å¤©', '4-7å¤©', '8-14å¤©', '15-30å¤©', '31-60å¤©', '61å¤©ä»¥ä¸Š']:
                    if interval_label in interval_comp:
                        data = interval_comp[interval_label]
                        cm0_count = data.get('CM0', {}).get('count', 0)
                        cm1_count = data.get('CM1', {}).get('count', 0)
                        cm2_count = data.get('CM2', {}).get('count', 0)
                        report.append(f"| {interval_label} | {cm0_count} | {cm1_count} | {cm2_count} |")
                
                report.append("")
        
        # å…³é”®æ´å¯Ÿ
        report.append("## ğŸ’¡ å…³é”®æ´å¯Ÿ")
        report.append("")
        
        vehicle_results = self.analysis_results.get('vehicle_analysis', {})
        if len(vehicle_results) >= 2:
            # è½¬åŒ–ç‡å¯¹æ¯”
            conversion_rates = {v: data['conversion_rate'] for v, data in vehicle_results.items()}
            best_vehicle = max(conversion_rates.keys(), key=lambda x: conversion_rates[x])
            worst_vehicle = min(conversion_rates.keys(), key=lambda x: conversion_rates[x])
            
            report.append("**è½¬åŒ–ç‡è¡¨ç°**:")
            report.append(f"- æœ€é«˜è½¬åŒ–ç‡: **{best_vehicle}** ({conversion_rates[best_vehicle]:.2f}%)")
            report.append(f"- æœ€ä½è½¬åŒ–ç‡: **{worst_vehicle}** ({conversion_rates[worst_vehicle]:.2f}%)")
            report.append("")
            
            # è®¢å•è§„æ¨¡å¯¹æ¯”
            order_counts = {v: data['total_presale_orders'] for v, data in vehicle_results.items()}
            max_orders_vehicle = max(order_counts.keys(), key=lambda x: order_counts[x])
            
            report.append("**è®¢å•è§„æ¨¡**:")
            report.append(f"- æœ€å¤§è®¢å•é‡: **{max_orders_vehicle}** ({order_counts[max_orders_vehicle]:,}å•)")
            report.append("")
            
            # æ—¶é—´é—´éš”æ´å¯Ÿ
            if 'time_interval_analysis' in self.analysis_results:
                time_analysis = self.analysis_results['time_interval_analysis']
                if 'comparison_summary' in time_analysis:
                    summary = time_analysis['comparison_summary']
                    avg_intervals = {v: data['avg_interval_days'] for v, data in summary.items()}
                    fastest_vehicle = min(avg_intervals.keys(), key=lambda x: avg_intervals[x])
                    slowest_vehicle = max(avg_intervals.keys(), key=lambda x: avg_intervals[x])
                    
                    report.append("**æ—¶é—´é—´éš”è¡¨ç°**:")
                    report.append(f"- æœ€å¿«é”å•: **{fastest_vehicle}** (å¹³å‡{avg_intervals[fastest_vehicle]:.1f}å¤©)")
                    report.append(f"- æœ€æ…¢é”å•: **{slowest_vehicle}** (å¹³å‡{avg_intervals[slowest_vehicle]:.1f}å¤©)")
                    report.append("")
            
        # æ–¹æ³•è¯´æ˜
        report.append("## ğŸ“‹ è®¡ç®—æ–¹æ³•è¯´æ˜")
        report.append("")
        report.append("**æŒ‡æ ‡å®šä¹‰**:")
        report.append("- **é¢„å”®ç´¯è®¡å°è®¢æ•°**: åœ¨é¢„å”®å‘¨æœŸå†…ï¼ˆä»é¢„å”®å¼€å§‹åˆ°é¢„å”®ç»“æŸï¼‰æ”¯ä»˜æ„å‘é‡‘çš„è®¢å•æ€»æ•°")
        report.append("- **å°è®¢ç•™å­˜é”å•æ•°**: é¢„å”®è®¢å•ä¸­ï¼Œåœ¨é¢„å”®ç»“æŸåå®Œæˆé”å•çš„è®¢å•æ•°é‡")
        report.append("- **å°è®¢è½¬åŒ–ç‡**: å°è®¢ç•™å­˜é”å•æ•° Ã· é¢„å”®ç´¯è®¡å°è®¢æ•° Ã— 100%")
        report.append("")
        report.append("**æ•°æ®æ¥æº**:")
        report.append("- æ•°æ®æ–‡ä»¶: intention_order_analysis.parquet")
        report.append("- ä¸šåŠ¡å®šä¹‰: business_definition.json")
        report.append("- åˆ†ææ—¶é—´: åŸºäºå„è½¦å‹é¢„å”®å‘¨æœŸå®šä¹‰")
        report.append("")
        
        return "\n".join(report)
        
    def save_report(self, filename: str = None):
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""
        if not filename:
            filename = f"cm_vehicle_presale_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
            
        report_content = self.generate_markdown_report()
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(report_content)
            
        logger.info(f"åˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³: {filename}")
        return filename

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºåˆ†æå™¨
        analyzer = CMVehiclePresaleAnalyzer()
        
        # åŠ è½½æ•°æ®
        analyzer.load_data()
        analyzer.load_business_definition()
        
        # æ‰§è¡Œåˆ†æ
        results = analyzer.analyze_all_cm_vehicles()
        
        if not results:
            logger.error("åˆ†æå¤±è´¥ï¼Œæ— æœ‰æ•ˆç»“æœ")
            return
            
        # ç”Ÿæˆå¹¶ä¿å­˜æŠ¥å‘Š
        report_file = analyzer.save_report()
        
        # è¾“å‡ºå¯¹æ¯”è¡¨æ ¼åˆ°æ§åˆ¶å°
        print("\n" + "="*80)
        print("CMè½¦å‹é¢„å”®åˆ†æç»“æœ")
        print("="*80)
        
        comparison_df = analyzer.generate_comparison_table()
        if not comparison_df.empty:
            print("\nè½¦å‹å¯¹æ¯”è¡¨:")
            print(comparison_df.to_string(index=False))
        
        print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
        print("="*80)
        
    except Exception as e:
        logger.error(f"åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")
        raise

if __name__ == "__main__":
    main()