"""
æ‡‚è½¦å¸å†…å®¹æå–å™¨ - Gradio Webåº”ç”¨

ä¸€ä¸ªç”¨æˆ·å‹å¥½çš„å‰ç«¯ç•Œé¢ï¼Œç”¨äºæå–å’Œå±•ç¤ºæ‡‚è½¦å¸ç¤¾åŒºé¡µé¢çš„ç”¨æˆ·å‘å¸ƒå†…å®¹
åŒ…å«AIé—®ç­”æ£€ç´¢åŠŸèƒ½ï¼ŒåŸºäºDeepSeek API
"""

import gradio as gr
import sys
import os
import time
import json
import requests
from datetime import datetime
from typing import Tuple, List, Dict, Any

# æ·»åŠ skillsç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'skills'))

from enhanced_content_extractor import EnhancedContentExtractor


class AIQARetriever:
    """AIé—®ç­”æ£€ç´¢å™¨"""
    
    def __init__(self):
        self.api_key = "sk-d7b34ad3d34e40218e1674383b400702"
        self.base_url = "https://api.deepseek.com/v1/chat/completions"
        self.data_file = "/Users/zihao_/Documents/github/W35_workflow/report/batch_extracted_content_20251010_135757.json"
        self.posts_data = None
        self._load_data()
    
    def _load_data(self):
        """åŠ è½½JSONæ•°æ®"""
        try:
            with open(self.data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.posts_data = data.get('posts', [])
                print(f"âœ… æˆåŠŸåŠ è½½ {len(self.posts_data)} æ¡å†…å®¹æ•°æ®")
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {str(e)}")
            self.posts_data = []
    
    def _filter_posts_by_time(self, start_date: str = None, end_date: str = None) -> List[Dict]:
        """
        æ ¹æ®æ—¶é—´èŒƒå›´è¿‡æ»¤å¸–å­æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD æ ¼å¼)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD æ ¼å¼)
            
        Returns:
            è¿‡æ»¤åçš„å¸–å­åˆ—è¡¨
        """
        if not self.posts_data:
            return []
        
        filtered_posts = []
        
        for post in self.posts_data:
            timestamp = post.get('timestamp', '')
            if not timestamp:
                continue
            
            # æå–æ—¥æœŸéƒ¨åˆ† (YYYY-MM-DD)
            post_date = timestamp.split(' ')[0] if ' ' in timestamp else timestamp
            
            # æ£€æŸ¥æ˜¯å¦åœ¨æ—¶é—´èŒƒå›´å†…
            include_post = True
            
            if start_date and post_date < start_date:
                include_post = False
            
            if end_date and post_date > end_date:
                include_post = False
            
            if include_post:
                filtered_posts.append(post)
        
        return filtered_posts
    
    def get_time_range_info(self) -> Tuple[str, str, int]:
        """
        è·å–æ•°æ®çš„æ—¶é—´èŒƒå›´ä¿¡æ¯
        
        Returns:
            Tuple[æœ€æ—©æ—¥æœŸ, æœ€æ™šæ—¥æœŸ, æ€»æ•°æ®é‡]
        """
        if not self.posts_data:
            return "", "", 0
        
        dates = []
        for post in self.posts_data:
            timestamp = post.get('timestamp', '')
            if timestamp:
                post_date = timestamp.split(' ')[0] if ' ' in timestamp else timestamp
                dates.append(post_date)
        
        if dates:
            dates.sort()
            return dates[0], dates[-1], len(self.posts_data)
        
        return "", "", len(self.posts_data)
    
    def _save_filtered_dataset(self, filtered_posts: List[Dict], question: str, start_date: str = None, end_date: str = None) -> str:
        """
        ä¿å­˜ç­›é€‰åçš„æ•°æ®é›†ä¸ºJSONæ–‡ä»¶
        
        Args:
            filtered_posts: ç­›é€‰åçš„å¸–å­æ•°æ®
            question: ç”¨æˆ·é—®é¢˜
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        # ç¡®ä¿reportç›®å½•å­˜åœ¨
        report_dir = os.path.join(os.path.dirname(__file__), 'report')
        os.makedirs(report_dir, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"filtered_dataset_{timestamp}.json"
        file_path = os.path.join(report_dir, filename)
        
        # æ„å»ºæ•°æ®é›†ä¿¡æ¯
        dataset_info = {
            "filter_info": {
                "question": question,
                "start_date": start_date or "ä¸é™",
                "end_date": end_date or "ä¸é™",
                "filter_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "original_count": len(self.posts_data),
                "filtered_count": len(filtered_posts)
            },
            "time_range": {
                "earliest": min([post.get('timestamp', '') for post in filtered_posts]) if filtered_posts else "",
                "latest": max([post.get('timestamp', '') for post in filtered_posts]) if filtered_posts else ""
            },
            "posts": filtered_posts
        }
        
        # ä¿å­˜æ–‡ä»¶
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(dataset_info, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ç­›é€‰æ•°æ®é›†å·²ä¿å­˜: {filename}")
            return file_path
        except Exception as e:
            print(f"âŒ ä¿å­˜ç­›é€‰æ•°æ®é›†å¤±è´¥: {str(e)}")
            return ""
    
    def _call_deepseek_api(self, messages: List[Dict[str, str]]) -> str:
        """è°ƒç”¨DeepSeek APIï¼ŒåŒ…å«é‡è¯•æœºåˆ¶"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "deepseek-chat",
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 2000
        }
        
        # é‡è¯•æœºåˆ¶
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°60ç§’
                response = requests.post(self.base_url, headers=headers, json=payload, timeout=60)
                response.raise_for_status()
                
                result = response.json()
                return result['choices'][0]['message']['content']
                
            except requests.exceptions.Timeout:
                if attempt < max_retries - 1:
                    print(f"âš ï¸ APIè°ƒç”¨è¶…æ—¶ï¼Œæ­£åœ¨é‡è¯• ({attempt + 1}/{max_retries})...")
                    time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                    continue
                else:
                    return f"APIè°ƒç”¨å¤±è´¥: è¿æ¥è¶…æ—¶ï¼Œå·²é‡è¯•{max_retries}æ¬¡"
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"âš ï¸ APIè°ƒç”¨å‡ºé”™ï¼Œæ­£åœ¨é‡è¯• ({attempt + 1}/{max_retries}): {str(e)}")
                    time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                    continue
                else:
                    return f"APIè°ƒç”¨å¤±è´¥: {str(e)}"
    
    def search_and_answer(self, question: str, start_date: str = None, end_date: str = None, progress=gr.Progress()) -> Tuple[str, str, str]:
        """
        åŸºäºå†…å®¹æ•°æ®å›ç­”ç”¨æˆ·é—®é¢˜
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD æ ¼å¼)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD æ ¼å¼)
            progress: Gradioè¿›åº¦æ¡
            
        Returns:
            Tuple[å›ç­”å†…å®¹, å¤„ç†æ—¥å¿—, ç­›é€‰æ•°æ®é›†æ–‡ä»¶è·¯å¾„]
        """
        if not question or not question.strip():
            return "âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜", "", ""
        
        if not self.posts_data:
            return "âŒ æ•°æ®æ–‡ä»¶æœªåŠ è½½æˆåŠŸï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„", "", ""
        
        progress(0.1, desc="æ­£åœ¨åˆ†æé—®é¢˜...")
        
        # æ ¹æ®æ—¶é—´èŒƒå›´è¿‡æ»¤æ•°æ®
        filtered_posts = self._filter_posts_by_time(start_date, end_date)
        
        if not filtered_posts:
            time_info = f"æ—¶é—´èŒƒå›´ï¼š{start_date or 'ä¸é™'} åˆ° {end_date or 'ä¸é™'}"
            return f"âŒ åœ¨æŒ‡å®šçš„æ—¶é—´èŒƒå›´å†…æ²¡æœ‰æ‰¾åˆ°æ•°æ®ã€‚{time_info}", "", ""
        
        print(f"ğŸ” æ—¶é—´è¿‡æ»¤ï¼šä» {len(self.posts_data)} æ¡æ•°æ®ä¸­ç­›é€‰å‡º {len(filtered_posts)} æ¡")
        
        # ä½¿ç”¨è¿‡æ»¤åçš„æ•°æ®æ›¿æ¢åŸå§‹æ•°æ®è¿›è¡Œåˆ†æ
        original_posts = self.posts_data
        self.posts_data = filtered_posts
        
        # æ„å»ºç³»ç»Ÿæç¤º
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ±½è½¦è¡Œä¸šåˆ†æå¸ˆï¼Œæ“…é•¿åˆ†æç”¨æˆ·è¯„è®ºå’Œåé¦ˆã€‚
ä½ å°†åŸºäºæä¾›çš„æ‡‚è½¦å¸ç¤¾åŒºç”¨æˆ·è¯„è®ºæ•°æ®æ¥å›ç­”é—®é¢˜ã€‚
è¯·ä»”ç»†åˆ†ææ‰€æœ‰ç›¸å…³å†…å®¹ï¼Œæä¾›å‡†ç¡®ã€å®¢è§‚ã€æœ‰è§åœ°çš„å›ç­”ã€‚
å›ç­”è¦æ±‚ï¼š
1. åŸºäºå®é™…æ•°æ®å†…å®¹å›ç­”ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
2. å¦‚æœæ•°æ®ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜
3. æä¾›å…·ä½“çš„æ•°æ®æ”¯æ’‘å’Œç”¨æˆ·è¯„è®ºå¼•ç”¨
4. åˆ†æè¦å®¢è§‚ä¸­ç«‹ï¼Œé¿å…ä¸»è§‚åè§
5. å›ç­”è¦ç»“æ„æ¸…æ™°ï¼Œä¾¿äºç†è§£"""
        
        # åˆ†æ‰¹å¤„ç†å†…å®¹ï¼Œé¿å…å•æ¬¡è¯·æ±‚è¿‡å¤§ - "ä¸€ç›®åè¡Œ"
        batch_size = 10
        total_batches = (len(self.posts_data) + batch_size - 1) // batch_size
        
        relevant_contents = []
        processing_log = []
        
        progress(0.2, desc="å¼€å§‹åˆ†æå†…å®¹æ•°æ®...")
        
        for batch_idx in range(total_batches):
            start_idx = batch_idx * batch_size
            end_idx = min((batch_idx + 1) * batch_size, len(self.posts_data))
            batch_posts = self.posts_data[start_idx:end_idx]
            
            # æ›´æ–°è¿›åº¦
            current_progress = 0.2 + (batch_idx / total_batches) * 0.6
            progress(current_progress, desc=f"æ­£åœ¨åˆ†æç¬¬ {batch_idx + 1}/{total_batches} æ‰¹å†…å®¹...")
            
            print(f"ğŸ” æ­£åœ¨åˆ†æç¬¬ {batch_idx + 1}/{total_batches} æ‰¹å†…å®¹ ({start_idx + 1}-{end_idx}/{len(self.posts_data)})")
            processing_log.append(f"åˆ†æç¬¬ {batch_idx + 1}/{total_batches} æ‰¹å†…å®¹ ({start_idx + 1}-{end_idx}/{len(self.posts_data)})")
            
            # æ„å»ºæ‰¹æ¬¡å†…å®¹æ‘˜è¦
            batch_content = ""
            for i, post in enumerate(batch_posts):
                content_preview = post.get('content', '')[:200] + "..." if len(post.get('content', '')) > 200 else post.get('content', '')
                batch_content += f"""
å†…å®¹ {start_idx + i + 1}:
ç”¨æˆ·: {post.get('username', 'æœªçŸ¥')}
æ—¶é—´: {post.get('timestamp', 'æœªçŸ¥')}
äº’åŠ¨: ç‚¹èµ{post.get('interactions', {}).get('likes', 0)}æ¬¡, è¯„è®º{post.get('interactions', {}).get('comments', 0)}æ¬¡
å†…å®¹: {content_preview}
è´¨é‡åˆ†æ•°: {post.get('quality_score', 0)}
---
"""
            
            # è¯¢é—®AIè¿™æ‰¹å†…å®¹æ˜¯å¦ä¸é—®é¢˜ç›¸å…³
            relevance_messages = [
                {"role": "system", "content": "ä½ éœ€è¦åˆ¤æ–­ä»¥ä¸‹ç”¨æˆ·è¯„è®ºå†…å®¹æ˜¯å¦ä¸ç”¨æˆ·é—®é¢˜ç›¸å…³ã€‚å¦‚æœç›¸å…³ï¼Œè¯·æå–å…³é”®ä¿¡æ¯ï¼›å¦‚æœä¸ç›¸å…³ï¼Œè¯·å›ç­”'ä¸ç›¸å…³'ã€‚"},
                {"role": "user", "content": f"ç”¨æˆ·é—®é¢˜ï¼š{question}\n\nè¯„è®ºå†…å®¹ï¼š{batch_content}\n\nè¯·åˆ¤æ–­è¿™äº›å†…å®¹æ˜¯å¦ä¸é—®é¢˜ç›¸å…³ï¼Œå¦‚æœç›¸å…³è¯·æå–å…³é”®ä¿¡æ¯ã€‚"}
            ]
            
            relevance_result = self._call_deepseek_api(relevance_messages)
            
            if "ä¸ç›¸å…³" not in relevance_result and len(relevance_result) > 10:
                relevant_contents.append(relevance_result)
                processing_log.append(f"âœ… ç¬¬ {batch_idx + 1} æ‰¹å‘ç°ç›¸å…³å†…å®¹")
            else:
                processing_log.append(f"âšª ç¬¬ {batch_idx + 1} æ‰¹æ— ç›¸å…³å†…å®¹")
        
        progress(0.8, desc="æ­£åœ¨ç”Ÿæˆæœ€ç»ˆå›ç­”...")
        
        if not relevant_contents:
            final_answer = "æ ¹æ®åˆ†ææ‰€æœ‰925æ¡ç”¨æˆ·è¯„è®ºï¼Œæ²¡æœ‰æ‰¾åˆ°ä¸æ‚¨é—®é¢˜ç›´æ¥ç›¸å…³çš„å†…å®¹ã€‚è¯·å°è¯•è°ƒæ•´é—®é¢˜æˆ–æä¾›æ›´å…·ä½“çš„å…³é”®è¯ã€‚"
            processing_log.append("âŒ æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")
        else:
            # åŸºäºç›¸å…³å†…å®¹ç”Ÿæˆæœ€ç»ˆå›ç­”
            combined_content = "\n\n".join(relevant_contents)
            final_messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ç”¨æˆ·é—®é¢˜ï¼š{question}\n\nç›¸å…³å†…å®¹åˆ†æï¼š\n{combined_content}\n\nè¯·åŸºäºä»¥ä¸Šå†…å®¹ç»™å‡ºè¯¦ç»†ã€å‡†ç¡®çš„å›ç­”ã€‚"}
            ]
            
            final_answer = self._call_deepseek_api(final_messages)
            processing_log.append(f"âœ… åŸºäº {len(relevant_contents)} æ‰¹ç›¸å…³å†…å®¹ç”Ÿæˆå›ç­”")
        
        progress(1.0, desc="åˆ†æå®Œæˆï¼")
        
        # ä¿å­˜ç­›é€‰åçš„æ•°æ®é›†
        filtered_dataset_path = self._save_filtered_dataset(filtered_posts, question, start_date, end_date)
        
        # æ¢å¤åŸå§‹æ•°æ®
        self.posts_data = original_posts
        
        # æ ¼å¼åŒ–å¤„ç†æ—¥å¿—
        log_text = "\n".join(processing_log)
        
        return final_answer, log_text, filtered_dataset_path


class ContentExtractorApp:
    """å†…å®¹æå–å™¨åº”ç”¨"""
    
    def __init__(self):
        self.extractor = EnhancedContentExtractor()
        self.ai_qa = AIQARetriever()
        self.last_result = None
    
    def extract_content(self, url: str, progress=gr.Progress()) -> Tuple[str, str, str]:
        """
        æå–å†…å®¹çš„ä¸»è¦å‡½æ•°
        
        Args:
            url: è¦æå–çš„ç½‘é¡µURL
            progress: Gradioè¿›åº¦æ¡
            
        Returns:
            Tuple[ç»Ÿè®¡ä¿¡æ¯, æ ¼å¼åŒ–å†…å®¹, ä¸‹è½½é“¾æ¥]
        """
        if not url or not url.strip():
            return "âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„URL", "", ""
        
        url = url.strip()
        
        # éªŒè¯URLæ ¼å¼
        if not (url.startswith('http://') or url.startswith('https://')):
            return "âŒ URLæ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·è¾“å…¥å®Œæ•´çš„ç½‘å€ï¼ˆåŒ…å«http://æˆ–https://ï¼‰", "", ""
        
        try:
            progress(0.1, desc="æ­£åœ¨è¿æ¥ç½‘ç«™...")
            
            # æ‰§è¡Œå†…å®¹æå–
            progress(0.3, desc="æ­£åœ¨åˆ†æç½‘é¡µç»“æ„...")
            result = self.extractor.analyze_and_extract(url)
            
            if not result["success"]:
                return f"âŒ æå–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}", "", ""
            
            progress(0.7, desc="æ­£åœ¨æ ¼å¼åŒ–å†…å®¹...")
            
            # ä¿å­˜ç»“æœä¾›ä¸‹è½½
            self.last_result = result
            
            # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
            stats_info = self._generate_stats_info(result)
            
            # ç”Ÿæˆæ ¼å¼åŒ–å†…å®¹å±•ç¤º
            formatted_content = self._generate_formatted_content(result)
            
            progress(0.9, desc="æ­£åœ¨ç”Ÿæˆä¸‹è½½æ–‡ä»¶...")
            
            # ç”Ÿæˆä¸‹è½½æ–‡ä»¶
            download_file = self._save_result_file(result)
            
            progress(1.0, desc="æå–å®Œæˆï¼")
            
            return stats_info, formatted_content, download_file
            
        except Exception as e:
            error_msg = f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            return error_msg, "", ""
    
    def _generate_stats_info(self, result: Dict[str, Any]) -> str:
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        summary = result.get('summary', {})
        
        stats = f"""
## ğŸ“Š æå–ç»Ÿè®¡ä¿¡æ¯

**ğŸ”— URL:** {result['url']}
**â° æå–æ—¶é—´:** {result['analysis_time']}

### ğŸ“ˆ æ•°æ®æ¦‚è§ˆ
- **åŸå§‹å†…å®¹æ•°:** {result['total_raw_posts']} æ¡
- **é«˜è´¨é‡å†…å®¹æ•°:** {result['total_posts']} æ¡
- **è¿‡æ»¤ç‡:** {((result['total_raw_posts'] - result['total_posts']) / result['total_raw_posts'] * 100):.1f}% (å·²è¿‡æ»¤ä½è´¨é‡å†…å®¹)

### ğŸ“ å†…å®¹åˆ†æ
- **æ€»å­—ç¬¦æ•°:** {summary.get('total_content_length', 0):,} å­—ç¬¦
- **å¹³å‡é•¿åº¦:** {summary.get('average_content_length', 0):.1f} å­—ç¬¦/æ¡
- **å¹³å‡è´¨é‡åˆ†æ•°:** {summary.get('average_quality_score', 0):.2f}/10

### ğŸ·ï¸ å†…å®¹ç‰¹å¾
- **åŒ…å«ç”¨æˆ·å:** {summary.get('posts_with_username', 0)} æ¡
- **åŒ…å«æ—¶é—´æˆ³:** {summary.get('posts_with_timestamp', 0)} æ¡
- **åŒ…å«å›¾ç‰‡:** {summary.get('posts_with_images', 0)} æ¡
- **åŒ…å«äº’åŠ¨æ•°æ®:** {summary.get('posts_with_interactions', 0)} æ¡
"""
        return stats
    
    def _generate_formatted_content(self, result: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ ¼å¼åŒ–çš„å†…å®¹å±•ç¤º"""
        posts = result.get('posts', [])
        
        if not posts:
            return "âŒ æœªæå–åˆ°æœ‰æ•ˆå†…å®¹"
        
        content_display = f"## ğŸ“‹ æå–åˆ°çš„ç”¨æˆ·å†…å®¹ ({len(posts)} æ¡)\n\n"
        
        for i, post in enumerate(posts[:10], 1):  # åªæ˜¾ç¤ºå‰10æ¡
            content_display += f"### ã€å†…å®¹ {i}ã€‘\n"
            
            # ç”¨æˆ·ä¿¡æ¯
            if post.get('username'):
                content_display += f"**ğŸ‘¤ ç”¨æˆ·:** {post['username']}\n"
            
            # æ—¶é—´ä¿¡æ¯
            if post.get('timestamp'):
                content_display += f"**ğŸ•’ æ—¶é—´:** {post['timestamp']}\n"
            
            # äº’åŠ¨æ•°æ®
            interactions = post.get('interactions', {})
            if interactions:
                interaction_parts = []
                if 'likes' in interactions:
                    interaction_parts.append(f"ğŸ‘ {interactions['likes']}ç‚¹èµ")
                if 'comments' in interactions:
                    interaction_parts.append(f"ğŸ’¬ {interactions['comments']}è¯„è®º")
                if 'shares' in interactions:
                    interaction_parts.append(f"ğŸ”„ {interactions['shares']}åˆ†äº«")
                
                if interaction_parts:
                    content_display += f"**ğŸ“Š äº’åŠ¨:** {' | '.join(interaction_parts)}\n"
            
            # å›¾ç‰‡ä¿¡æ¯
            if post.get('images'):
                content_display += f"**ğŸ–¼ï¸ å›¾ç‰‡:** {len(post['images'])} å¼ \n"
            
            # è´¨é‡åˆ†æ•°
            if 'quality_score' in post:
                content_display += f"**â­ è´¨é‡åˆ†æ•°:** {post['quality_score']:.1f}/10\n"
            
            # å†…å®¹æ–‡æœ¬
            content = post.get('content', '')
            if len(content) > 300:
                content = content[:300] + "..."
            content_display += f"**ğŸ“„ å†…å®¹:**\n{content}\n"
            
            content_display += "\n---\n\n"
        
        if len(posts) > 10:
            content_display += f"*æ³¨ï¼šä»…æ˜¾ç¤ºå‰10æ¡å†…å®¹ï¼Œå®Œæ•´å†…å®¹è¯·ä¸‹è½½æ–‡ä»¶æŸ¥çœ‹ï¼ˆå…±{len(posts)}æ¡ï¼‰*\n"
        
        return content_display
    
    def _save_result_file(self, result: Dict[str, Any]) -> str:
        """ä¿å­˜ç»“æœæ–‡ä»¶å¹¶è¿”å›æ–‡ä»¶è·¯å¾„"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"extracted_content_{timestamp}.txt"
        
        # è®¾ç½®ä¿å­˜è·¯å¾„ä¸º report ç›®å½•
        report_dir = os.path.join(os.path.dirname(__file__), 'report')
        
        # ç¡®ä¿ report ç›®å½•å­˜åœ¨
        os.makedirs(report_dir, exist_ok=True)
        
        filepath = os.path.join(report_dir, filename)
        
        posts = result.get('posts', [])
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("æ‡‚è½¦å¸ç”¨æˆ·å†…å®¹æå–ç»“æœ\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"URL: {result['url']}\n")
            f.write(f"æå–æ—¶é—´: {result['analysis_time']}\n")
            f.write(f"æ€»è®¡: {len(posts)} æ¡å†…å®¹\n")
            f.write("=" * 50 + "\n\n")
            
            for i, post in enumerate(posts, 1):
                f.write(f"ã€å†…å®¹ {i}ã€‘\n")
                
                if post.get('username'):
                    f.write(f"ç”¨æˆ·: {post['username']}\n")
                
                if post.get('timestamp'):
                    f.write(f"æ—¶é—´: {post['timestamp']}\n")
                
                interactions = post.get('interactions', {})
                if interactions:
                    interaction_parts = []
                    for key, value in interactions.items():
                        if key == 'likes':
                            interaction_parts.append(f"likes: {value}")
                        elif key == 'comments':
                            interaction_parts.append(f"comments: {value}")
                        elif key == 'shares':
                            interaction_parts.append(f"shares: {value}")
                    
                    if interaction_parts:
                        f.write(f"äº’åŠ¨: {', '.join(interaction_parts)}\n")
                
                f.write(f"å†…å®¹: {post.get('content', '')}\n")
                
                if post.get('images'):
                    f.write(f"å›¾ç‰‡: {len(post['images'])} å¼ \n")
                
                f.write("-" * 50 + "\n\n")
        
        return filepath


def create_app():
    """åˆ›å»ºGradioåº”ç”¨"""
    app = ContentExtractorApp()
    
    # è‡ªå®šä¹‰CSSæ ·å¼
    custom_css = """
    .main-container {
        max-width: 1200px;
        margin: 0 auto;
    }
    .header {
        text-align: center;
        padding: 20px;
        background: linear-gradient(135deg, #C8D0D9 0%, #ffffff 100%);
        color: white;
        border-radius: 10px;
        margin-bottom: 20px;
    }
    .stats-box {
        background: #f8f9fa;
        border-left: 4px solid #007bff;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
    .content-box {
        background: #ffffff;
        border: 1px solid #dee2e6;
        border-radius: 8px;
        padding: 15px;
        margin: 10px 0;
    }
    """
    
    with gr.Blocks(css=custom_css, title="æ‡‚è½¦å¸å†…å®¹æå–å™¨ & AIé—®ç­”æ£€ç´¢") as demo:
        gr.HTML("""
        <div class="header">
            <h1>ğŸš— æ‡‚è½¦å¸å†…å®¹æå–å™¨ & AIé—®ç­”æ£€ç´¢</h1>
            <p>æ™ºèƒ½æå–æ‡‚è½¦å¸ç¤¾åŒºé¡µé¢çš„ç”¨æˆ·å‘å¸ƒå†…å®¹ï¼Œæ”¯æŒå†…å®¹è¿‡æ»¤å’Œæ ¼å¼åŒ–ï¼Œä»¥åŠåŸºäºDeepSeek AIçš„é—®ç­”æ£€ç´¢</p>
        </div>
        """)
        
        with gr.Tabs():
            # ç¬¬ä¸€ä¸ªæ ‡ç­¾é¡µï¼šå†…å®¹æå–
            with gr.TabItem("ğŸ“¥ å†…å®¹æå–"):
                with gr.Row():
                    with gr.Column(scale=3):
                        url_input = gr.Textbox(
                            label="ğŸ”— è¯·è¾“å…¥æ‡‚è½¦å¸ç¤¾åŒºé¡µé¢URL",
                            placeholder="ä¾‹å¦‚: https://www.dongchedi.com/community/9118/hot-release-49",
                            lines=1
                        )
                    
                    with gr.Column(scale=1):
                        extract_btn = gr.Button(
                            "ğŸš€ å¼€å§‹æå–",
                            variant="primary",
                            size="lg"
                        )
                
                # ç¤ºä¾‹URL
                gr.HTML("""
                <div style="margin: 10px 0; padding: 10px; background: #e3f2fd; border-radius: 5px;">
                    <strong>ğŸ’¡ ç¤ºä¾‹URL:</strong><br>
                    â€¢ https://www.dongchedi.com/community/9118/hot-release-49<br>
                    â€¢ https://www.dongchedi.com/community/[å…¶ä»–ç¤¾åŒºID]/hot-release-[é¡µé¢ID]
                </div>
                """)
                
                # ç»“æœå±•ç¤ºåŒºåŸŸ
                with gr.Row():
                    with gr.Column(scale=1):
                        stats_output = gr.Markdown(
                            label="ğŸ“Š ç»Ÿè®¡ä¿¡æ¯",
                            elem_classes=["stats-box"]
                        )
                    
                    with gr.Column(scale=2):
                        content_output = gr.Markdown(
                            label="ğŸ“‹ æå–å†…å®¹",
                            elem_classes=["content-box"]
                        )
                
                # ä¸‹è½½åŒºåŸŸ
                download_file = gr.File(
                    label="ğŸ“¥ ä¸‹è½½å®Œæ•´ç»“æœæ–‡ä»¶",
                    visible=False
                )
                
                # ç»‘å®šäº‹ä»¶
                extract_btn.click(
                    fn=app.extract_content,
                    inputs=[url_input],
                    outputs=[stats_output, content_output, download_file],
                    show_progress=True
                ).then(
                    fn=lambda: gr.update(visible=True),
                    outputs=[download_file]
                )
                
                # æ·»åŠ è¯´æ˜
                gr.HTML("""
                <div style="margin-top: 30px; padding: 20px; background: #f8f9fa; border-radius: 8px;">
                    <h3>ğŸ“– ä½¿ç”¨è¯´æ˜</h3>
                    <ul>
                        <li><strong>è¾“å…¥URL:</strong> ç²˜è´´æ‡‚è½¦å¸ç¤¾åŒºé¡µé¢çš„å®Œæ•´é“¾æ¥</li>
                        <li><strong>ç‚¹å‡»æå–:</strong> ç³»ç»Ÿä¼šè‡ªåŠ¨åˆ†æé¡µé¢å¹¶æå–ç”¨æˆ·å‘å¸ƒçš„å†…å®¹</li>
                        <li><strong>æŸ¥çœ‹ç»“æœ:</strong> å·¦ä¾§æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼Œå³ä¾§æ˜¾ç¤ºæ ¼å¼åŒ–çš„å†…å®¹é¢„è§ˆ</li>
                        <li><strong>ä¸‹è½½æ–‡ä»¶:</strong> å¯ä¸‹è½½åŒ…å«æ‰€æœ‰æå–å†…å®¹çš„å®Œæ•´æ–‡æœ¬æ–‡ä»¶</li>
                    </ul>
                    
                    <h3>âœ¨ åŠŸèƒ½ç‰¹ç‚¹</h3>
                    <ul>
                        <li><strong>æ™ºèƒ½è¿‡æ»¤:</strong> è‡ªåŠ¨è¿‡æ»¤UIå…ƒç´ å’Œä½è´¨é‡å†…å®¹ï¼Œåªä¿ç•™çœŸå®ç”¨æˆ·å‘å¸ƒçš„å†…å®¹</li>
                        <li><strong>è´¨é‡è¯„åˆ†:</strong> åŸºäºå¤šç»´åº¦æŒ‡æ ‡å¯¹å†…å®¹è¿›è¡Œè´¨é‡è¯„åˆ†</li>
                        <li><strong>ç»“æ„åŒ–è¾“å‡º:</strong> åŒ…å«ç”¨æˆ·åã€æ—¶é—´ã€äº’åŠ¨æ•°æ®ã€å›¾ç‰‡ä¿¡æ¯ç­‰å®Œæ•´ä¿¡æ¯</li>
                        <li><strong>æ ¼å¼åŒ–å±•ç¤º:</strong> æ¸…æ™°çš„æ ¼å¼åŒ–å±•ç¤ºï¼Œä¾¿äºé˜…è¯»å’Œåˆ†æ</li>
                    </ul>
                </div>
                """)
            
            # ç¬¬äºŒä¸ªæ ‡ç­¾é¡µï¼šAIé—®ç­”æ£€ç´¢
            with gr.TabItem("ğŸ¤– AIé—®ç­”æ£€ç´¢"):
                gr.Markdown("""
                åŸºäºå·²æå–çš„æ‡‚è½¦å¸ç”¨æˆ·è¯„è®ºæ•°æ®ï¼Œä½¿ç”¨DeepSeek AIè¿›è¡Œæ™ºèƒ½é—®ç­”
                
                ğŸ’¡ **ä½¿ç”¨è¯´æ˜ï¼š**
                - è¾“å…¥æ‚¨æƒ³äº†è§£çš„é—®é¢˜ï¼ŒAIå°†åˆ†æç”¨æˆ·è¯„è®ºæ•°æ®
                - å¯é€‰æ‹©æ—¶é—´èŒƒå›´æ¥è¿‡æ»¤æ•°æ®ï¼Œæ§åˆ¶åˆ†æçš„æ•°æ®é‡
                - ç³»ç»Ÿä¼šé€æ‰¹åˆ†æå†…å®¹ï¼Œå¹¶æ˜¾ç¤ºå®æ—¶è¿›åº¦
                - åŸºäºç›¸å…³å†…å®¹ç”Ÿæˆå‡†ç¡®ã€å®¢è§‚çš„å›ç­”
                
                â° **æ—¶é—´è¿‡æ»¤ï¼š**
                - ç•™ç©ºè¡¨ç¤ºä¸é™åˆ¶æ—¶é—´èŒƒå›´ï¼Œåˆ†ææ‰€æœ‰æ•°æ®
                - è®¾ç½®å¼€å§‹/ç»“æŸæ—¥æœŸå¯ç¼©å°åˆ†æèŒƒå›´ï¼Œæé«˜æ•ˆç‡
                - æ—¥æœŸæ ¼å¼ï¼šYYYY-MM-DDï¼ˆå¦‚ï¼š2024-01-01ï¼‰
                """)
                
                with gr.Row():
                    with gr.Column(scale=4):
                        question_input = gr.Textbox(
                            label="ğŸ’¬ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜",
                            placeholder="ä¾‹å¦‚ï¼šç”¨æˆ·å¯¹è¿™æ¬¾è½¦çš„æ²¹è€—è¯„ä»·å¦‚ä½•ï¼Ÿæœ‰å“ªäº›å¸¸è§çš„è´¨é‡é—®é¢˜ï¼Ÿ",
                            lines=2
                        )
                    with gr.Column(scale=1):
                        qa_btn = gr.Button("ğŸ” AIåˆ†æ", variant="primary", size="lg")
                
                # æ—¶é—´èŒƒå›´è¿‡æ»¤æ§ä»¶
                with gr.Row():
                    with gr.Column(scale=2):
                        start_date = gr.Textbox(
                            label="ğŸ“… å¼€å§‹æ—¥æœŸ (å¯é€‰)",
                            placeholder="YYYY-MM-DDï¼Œå¦‚ï¼š2024-01-01",
                            value="",
                            lines=1
                        )
                    with gr.Column(scale=2):
                        end_date = gr.Textbox(
                            label="ğŸ“… ç»“æŸæ—¥æœŸ (å¯é€‰)",
                            placeholder="YYYY-MM-DDï¼Œå¦‚ï¼š2024-12-31",
                            value="",
                            lines=1
                        )
                    with gr.Column(scale=1):
                        # è·å–æ•°æ®æ—¶é—´èŒƒå›´ä¿¡æ¯
                        min_date, max_date, total_count = app.ai_qa.get_time_range_info()
                        time_info = gr.HTML(f"""
                        <div style="padding: 10px; background: #e8f5e8; border-radius: 5px; font-size: 12px;">
                            <strong>ğŸ“Š æ•°æ®èŒƒå›´ï¼š</strong><br>
                            â€¢ æœ€æ—©ï¼š{min_date}<br>
                            â€¢ æœ€æ™šï¼š{max_date}<br>
                            â€¢ æ€»è®¡ï¼š{total_count} æ¡
                        </div>
                        """)
                
                with gr.Row():
                    with gr.Column(scale=2):
                        answer_output = gr.Textbox(
                            label="ğŸ¯ AIå›ç­”",
                            lines=20,
                            max_lines=25,
                            show_copy_button=True
                        )
                    with gr.Column(scale=1):
                        log_output = gr.Textbox(
                            label="ğŸ“Š åˆ†æè¿›åº¦",
                            lines=20,
                            max_lines=25
                        )
                
                # ä¸‹è½½ç­›é€‰æ•°æ®é›†åŒºåŸŸ
                with gr.Row():
                    with gr.Column(scale=3):
                        gr.HTML("""
                        <div style="padding: 10px; background: #f0f8ff; border-radius: 5px; margin: 10px 0;">
                            <strong>ğŸ“¥ ç­›é€‰æ•°æ®é›†ä¸‹è½½</strong><br>
                            <small>AIåˆ†æå®Œæˆåï¼Œå¯ä¸‹è½½æœ¬æ¬¡ä½¿ç”¨çš„ç­›é€‰æ•°æ®é›†ï¼Œæ–¹ä¾¿å¤æŸ¥å¤§æ¨¡å‹å¤„ç†çš„å…·ä½“å†…å®¹</small>
                        </div>
                        """)
                    with gr.Column(scale=1):
                        filtered_dataset_file = gr.File(
                            label="ğŸ“Š ç­›é€‰æ•°æ®é›†",
                            visible=False,
                            file_count="single"
                        )
                
                # ç»‘å®šAIé—®ç­”äº‹ä»¶
                qa_btn.click(
                    fn=app.ai_qa.search_and_answer,
                    inputs=[question_input, start_date, end_date],
                    outputs=[answer_output, log_output, filtered_dataset_file],
                    show_progress=True
                ).then(
                    fn=lambda file_path: gr.update(visible=bool(file_path)),
                    inputs=[filtered_dataset_file],
                    outputs=[filtered_dataset_file]
                )
                
                # AIé—®ç­”ç¤ºä¾‹
                gr.Examples(
                    examples=[
                        ["ç”¨æˆ·å¯¹è¿™æ¬¾è½¦çš„æ²¹è€—è¡¨ç°å¦‚ä½•è¯„ä»·ï¼Ÿ"],
                        ["æœ‰å“ªäº›ç”¨æˆ·åæ˜ çš„è´¨é‡é—®é¢˜ï¼Ÿ"],
                        ["ç”¨æˆ·å¯¹è½¦è¾†çš„å¤–è§‚è®¾è®¡æœ‰ä»€ä¹ˆçœ‹æ³•ï¼Ÿ"],
                        ["å…³äºè½¦è¾†çš„æ€§ä»·æ¯”ï¼Œç”¨æˆ·æ€ä¹ˆè¯´ï¼Ÿ"],
                        ["ç”¨æˆ·å¯¹å”®åæœåŠ¡çš„è¯„ä»·å¦‚ä½•ï¼Ÿ"]
                    ],
                    inputs=[question_input]
                )
                
                # æ•°æ®æºä¿¡æ¯
                gr.Markdown(f"""
                ğŸ“Š **æ•°æ®æºä¿¡æ¯ï¼š**
                - æ•°æ®æ–‡ä»¶ï¼š`batch_extracted_content_20251010_135757.json`
                - æ•°æ®æ¥æºï¼šæ‡‚è½¦å¸ç¤¾åŒºç”¨æˆ·è¯„è®º
                - AIæ¨¡å‹ï¼šDeepSeek Chat
                
                ğŸ“¥ **ç­›é€‰æ•°æ®é›†ï¼š**
                - æ¯æ¬¡AIåˆ†æåä¼šç”Ÿæˆå¯¹åº”çš„ç­›é€‰æ•°æ®é›†æ–‡ä»¶
                - åŒ…å«æœ¬æ¬¡åˆ†æä½¿ç”¨çš„å…·ä½“æ•°æ®å†…å®¹
                - ä¾¿äºç”¨æˆ·å¤æŸ¥å’ŒéªŒè¯AIåˆ†æç»“æœ
                - æ–‡ä»¶æ ¼å¼ï¼šJSONï¼ŒåŒ…å«è¿‡æ»¤æ¡ä»¶ã€æ—¶é—´èŒƒå›´ã€æ•°æ®ç»Ÿè®¡ç­‰ä¿¡æ¯
                """)
    
    return demo


if __name__ == "__main__":
    # åˆ›å»ºå¹¶å¯åŠ¨åº”ç”¨
    demo = create_app()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
        quiet=False
    )